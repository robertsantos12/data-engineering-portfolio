# 🔄 ETL Pipeline with Spark & AWS  
This project showcases an **ETL pipeline using Apache Spark and AWS services (S3, Glue, Redshift)** to process large-scale data efficiently.  

## 🚀 Features  
- Extract data from multiple sources (CSV, JSON, API).  
- Transform data using **PySpark** for cleaning and aggregation.  
- Load processed data into **AWS Redshift** for analytics.  

## 🛠️ Tech Stack  
- **Apache Spark** (PySpark)  
- **AWS S3, Glue, Redshift**  
- **Airflow for scheduling**
